# Applied-AI-Model-of-ASL-Interpretation
Our initial machine-learning model was trained on a homogenous dataset of 78,000 images depicting a hand, showing a letter from the ASL alphabet, against a white background. 

Working in a team of 5 to enhance this pre-existing model with a three-pronged approach: 
1. Diversifying the photo dataset with colorful backgrounds
2. Modifying transforms to account for varying image clarity or color
3. Using edge detection to highlight hand shape.

My partner and I, focusing on dataset diversification, incorporated over 1500 photos from Kaggle datasets and original photos we took ourselves. This difference in data proportions was due to the computing power available to us. With training on the mixed dataset and testing it only on the new images, with diverse backgrounds, we reported a 7% accuracy increase in ASL recognition. 
